import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from src.vectorstore import get_vector_store
from src import CONFIG
from src.utils import format_docs, chat_stream
from chat_db import init_chat_table, load_conversations, save_message  # ajout DB

OPENAI_API_KEY = CONFIG["OPENAI_API_KEY"]
BASE_DIR = "./collections"

# --- VÃ©rification login ---
# --- VÃ©rification login ---
if "logged_in" not in st.session_state or not st.session_state.logged_in:
    st.error("ğŸš« AccÃ¨s refusÃ©. Veuillez vous connecter.")
    if st.button("ğŸ”‘ Retour Ã  la connexion"):
        st.switch_page("app.py")
    st.stop()

# --- VÃ©rification rÃ´le ---
if st.session_state.role == "admin":
    st.error("ğŸš« AccÃ¨s refusÃ©. Les admins ne peuvent pas accÃ©der au chat.")
    st.stop()

# --- Initialisation DB pour conversations ---
init_chat_table()
matricule = st.session_state["matricule"]

# Charger conversations depuis DB
if "conversations" not in st.session_state:
    st.session_state.conversations = load_conversations(matricule)
    if not st.session_state.conversations:
        st.session_state.conversations = {"Conversation 1": []}

if "active_conv" not in st.session_state:
    st.session_state.active_conv = list(st.session_state.conversations.keys())[0]

st.write(f"Bienvenue {st.session_state.nom} {st.session_state.prenom} ğŸ‘‹")

# --- Header avec bouton dÃ©connexion ---
col1, col2 = st.columns([8, 1])
with col1:
    st.title("ğŸ’¬ Interrogez vos documents")
with col2:
    if st.button("ğŸ”“ "):
        st.session_state.clear()
        st.switch_page("app.py")

# --- Sidebar : gestion des conversations ---
with st.sidebar:
    st.subheader("ğŸ’¬ Gestion des conversations")

    conv_names = list(st.session_state.conversations.keys())

    # SÃ©lection conversation
    selected_conv = st.selectbox(
        "ğŸ“‚ SÃ©lectionner une conversation",
        conv_names,
        index=conv_names.index(st.session_state.active_conv),
        key="conv_selectbox"
    )
    st.session_state.active_conv = selected_conv

    # Actions (nouvelle / supprimer)
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("â• Nouvelle", use_container_width=True):
            new_name = f"Conversation {len(conv_names) + 1}"
            st.session_state.conversations[new_name] = []
            st.session_state.active_conv = new_name
            st.rerun()

    with col2:
        if st.button("ğŸ—‘ï¸ Supprimer", use_container_width=True):
            conv_to_delete = st.session_state.active_conv

            # Supprimer en mÃ©moire
            st.session_state.conversations.pop(conv_to_delete, None)

            # Supprimer aussi en DB
            from chat_db import delete_conversation
            delete_conversation(matricule, conv_to_delete)

            # Rester sur une autre conv si dispo
            if st.session_state.conversations:
                st.session_state.active_conv = list(st.session_state.conversations.keys())[0]
            else:
                st.session_state.conversations = {"Conversation 1": []}
                st.session_state.active_conv = "Conversation 1"

            st.success(f"âœ… {conv_to_delete} supprimÃ©e.")
            st.rerun()


# --- PrÃ©paration du modÃ¨le et du retriever ---
vector_store = get_vector_store()
llm = ChatOpenAI(model="gpt-4o-mini", api_key=OPENAI_API_KEY, temperature=0.7)

template = """
Tu es Hugo, un assistant juridique spÃ©cialisÃ© dans le domaine bancaire. 
Ta mission est de rÃ©pondre uniquement aux questions juridiques relatives au secteur bancaire, en tâ€™appuyant exclusivement sur les documents fournis et les Ã©lÃ©ments de contexte.

RÃ¨gles de comportement :
- Si la question ne concerne pas le juridique ou le domaine bancaire, rÃ©ponds : Â« Merci de poser des questions juridiques dans le domaine bancaire ! Â».
- Si on te demande Â« Bonjour Â» ,Â« Parle-moi de toi Â», Â« Qui es-tu ? Â» ou Â« Que sais-tu faire ? Â», tu peux rÃ©pondre briÃ¨vement Ã  propos de ton rÃ´le.
- Si la rÃ©ponse nâ€™est pas prÃ©sente dans les documents ou que tu nâ€™en es pas certain, dis simplement que tu ne sais pas. Nâ€™invente jamais de rÃ©ponse.
- Donne toujours une rÃ©ponse claire, concise (maximum trois phrases).
- Termine toujours ta rÃ©ponse par : Â« merci de m'avoir posÃ© la question ! Â».

Contexte : {context}

Question : {question}
"""

prompt = PromptTemplate.from_template(template)

retriever = vector_store.as_retriever(
    search_type="similarity_score_threshold",
    search_kwargs={"score_threshold": 0.5, "k": 5}
)

chain = (
    {
        "context": retriever | format_docs,
        "question": RunnablePassthrough(),
    }
    | prompt
    | llm
    | StrOutputParser()
)

# --- Affichage de lâ€™historique ---
for msg in st.session_state.conversations[st.session_state.active_conv]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --- Input utilisateur ---
if user_input := st.chat_input("ğŸ’¬ Pose ta question ici..."):
    # Ajout + sauvegarde du message utilisateur
    st.session_state.conversations[st.session_state.active_conv].append(
        {"role": "user", "content": user_input}
    )
    save_message(matricule, st.session_state.active_conv, "user", user_input)

    with st.chat_message("user"):
        st.markdown(user_input)

    # GÃ©nÃ©ration rÃ©ponse
    response = chain.invoke(user_input)

    with st.spinner("GÃ©nÃ©ration de la rÃ©ponse..."):
        with st.chat_message("assistant"):
            stream_text = st.write_stream(chat_stream(response))

    # Ajout + sauvegarde du message assistant
    st.session_state.conversations[st.session_state.active_conv].append(
        {"role": "assistant", "content": response}
    )
    save_message(matricule, st.session_state.active_conv, "assistant", response)
